

"""
Insights generator module for the Incident Management Analytics application.
This module orchestrates the generation of insights from incident data.
"""

import logging
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple, Union
import json
from datetime import datetime

from models.llm_manager import LLMManager
from data.data_processor import DataProcessor
from data.data_validator import check_data_sufficiency

logger = logging.getLogger(__name__)

class InsightsGenerator:
    """
    Class for generating insights from incident data.
    """
    
    def __init__(self, config: Dict[str, Any], llm_manager: LLMManager, data_processor: DataProcessor):
        """
        Initialize the InsightsGenerator with application configuration.
        
        Args:
            config: Application configuration dictionary
            llm_manager: LLMManager instance for generating AI-powered insights
            data_processor: DataProcessor instance for preparing data for analysis
        """
        self.config = config
        self.llm_manager = llm_manager
        self.data_processor = data_processor
    
    # This can be placed at the end of insight_generator.py


    
    def generate_all_insights(self, 
                             df: pd.DataFrame,
                             user_api_key: Optional[str] = None) -> Dict[str, Dict[str, Any]]:
        """
        Generate all possible types of insights from incident data.
        
        Args:
            df: DataFrame with incident data
            user_api_key: Optional user-provided API key
            
        Returns:
            Dictionary with all generated insights
        """
        logger.info("Generating all possible insights")
        
        # Define all insight types to generate
        insight_types = [
            "incident_insights",
            "root_cause_analysis",
            "automation_opportunity",
            "resource_optimization",
            "predictive_analysis"
        ]
        
        all_insights = {}
        
        # Generate each type of insight
        for insight_type in insight_types:
            insights = self.generate_insights(df, insight_type, user_api_key)
            all_insights[insight_type] = insights
        
        return all_insights
    
    def _combine_insights(self, 
                         llm_insights: Dict[str, Any], 
                         metadata: Dict[str, Any],
                         insight_type: str) -> Dict[str, Any]:
        """
        Combine LLM-generated insights with data-derived insights.
        
        Args:
            llm_insights: Insights generated by the LLM
            metadata: Metadata from data processing
            insight_type: Type of insights
            
        Returns:
            Combined insights dictionary
        """
        # Start with LLM insights
        combined_insights = llm_insights.copy()
        
        # Add metadata about the insight generation
        combined_insights["insight_type"] = insight_type
        combined_insights["generated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Add data-derived insights from metadata
        combined_insights["data_insights"] = {}
        
        # Extract relevant metrics from metadata based on insight type
        if insight_type == "incident_insights":
            # Add time distribution insights
            if "time_bucket" in metadata:
                combined_insights["data_insights"]["time_distribution"] = metadata.get("incidents_per_time_bucket", {})
            
            # Add day of week distribution
            if "day_of_week_distribution" in metadata:
                combined_insights["data_insights"]["day_of_week"] = metadata.get("day_of_week_distribution", {})
            
            # Add seasonality insights
            if "seasonality" in metadata:
                combined_insights["data_insights"]["seasonality"] = metadata.get("seasonality", {})
        
        elif insight_type == "root_cause_analysis":
            # Add category distributions
            if "category_metrics" in metadata:
                combined_insights["data_insights"]["categories"] = metadata.get("category_metrics", {})
            
            # Add system insights
            if "system_metrics" in metadata:
                combined_insights["data_insights"]["systems"] = metadata.get("system_metrics", {})
        
        elif insight_type == "automation_opportunity":
            # Add identified patterns
            if "identified_patterns" in metadata:
                combined_insights["data_insights"]["patterns"] = metadata.get("identified_patterns", [])
            
            # Add text patterns
            if "text_patterns" in metadata:
                combined_insights["data_insights"]["text_patterns"] = metadata.get("text_patterns", {})
        
        elif insight_type == "resource_optimization":
            # Add resource metrics
            if "resource_metrics" in metadata:
                combined_insights["data_insights"]["resources"] = metadata.get("resource_metrics", {})
            
            # Add workload distribution
            if "workload_distribution" in metadata:
                combined_insights["data_insights"]["workload"] = metadata.get("workload_distribution", {})
        
        # Add generic data summary
        combined_insights["data_summary"] = {
            "incident_count": metadata.get("incident_count", 0),
            "analyzed_columns": list(metadata.get("column_mapping", {}).values()) if "column_mapping" in metadata else []
        }
        
        return combined_insights

    def get_key_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate key performance metrics from incident data for dashboard display.
        
        Args:
            df: DataFrame with incident data
            
        Returns:
            Dictionary with key metrics
        """
        metrics = {
            "total_incidents": len(df),
            "metrics_calculated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Time-based metrics
        if all(col in df.columns for col in ['created_date', 'resolved_date']):
            try:
                # Ensure date columns are datetime
                for col in ['created_date', 'resolved_date']:
                    if df[col].dtype != 'datetime64[ns]':
                        df[col] = pd.to_datetime(df[col], errors='coerce')
                
                # Calculate resolution time
                df['resolution_time_hours'] = (df['resolved_date'] - df['created_date']).dt.total_seconds() / 3600
                
                # Filter valid resolution times
                valid_df = df[(df['resolution_time_hours'] >= 0) & (df['resolution_time_hours'] < 8760)]  # < 1 year
                
                if len(valid_df) > 0:
                    # Calculate MTTR
                    mttr_hours = valid_df['resolution_time_hours'].mean()
                    metrics["mttr_hours"] = round(mttr_hours, 2)
                    metrics["mttr_days"] = round(mttr_hours / 24, 2)
                    
                    # Calculate resolution time percentiles
                    metrics["resolution_percentiles"] = {
                        "p50": round(valid_df['resolution_time_hours'].quantile(0.5), 2),
                        "p75": round(valid_df['resolution_time_hours'].quantile(0.75), 2),
                        "p90": round(valid_df['resolution_time_hours'].quantile(0.9), 2)
                    }
                    
                    # Calculate resolved incident count
                    metrics["resolved_count"] = len(valid_df)
                    metrics["resolution_rate"] = round(len(valid_df) / len(df) * 100, 2)
            except Exception as e:
                logger.warning(f"Error calculating time-based metrics: {str(e)}")
        
        # Priority distribution
        if 'priority' in df.columns:
            try:
                priority_counts = df['priority'].value_counts()
                metrics["priority_distribution"] = priority_counts.to_dict()
                
                # Calculate high priority percentage
                high_priorities = [p for p in priority_counts.index if str(p).lower() in ['critical', 'high', 'p1', 'p2', '1', '2']]
                high_priority_count = sum(priority_counts[p] for p in high_priorities if p in priority_counts)
                metrics["high_priority_percentage"] = round(high_priority_count / len(df) * 100, 2)
            except Exception as e:
                logger.warning(f"Error calculating priority metrics: {str(e)}")
        
        # Status distribution
        if 'status' in df.columns:
            try:
                status_counts = df['status'].value_counts()
                metrics["status_distribution"] = status_counts.to_dict()
                
                # Calculate open incident percentage
                open_statuses = [s for s in status_counts.index if str(s).lower() in ['open', 'in progress', 'new', 'assigned']]
                open_count = sum(status_counts[s] for s in open_statuses if s in status_counts)
                metrics["open_percentage"] = round(open_count / len(df) * 100, 2)
            except Exception as e:
                logger.warning(f"Error calculating status metrics: {str(e)}")
        
        # Recent trend
        if 'created_date' in df.columns:
            try:
                if df['created_date'].dtype != 'datetime64[ns]':
                    df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')
                
                # Group by day
                df['date'] = df['created_date'].dt.date
                daily_counts = df.groupby('date').size()
                
                if len(daily_counts) >= 2:
                    # Calculate recent trend (last 7 days vs previous 7 days)
                    sorted_days = sorted(daily_counts.index)
                    
                    if len(sorted_days) >= 14:
                        recent_days = sorted_days[-7:]
                        previous_days = sorted_days[-14:-7]
                        
                        recent_avg = daily_counts[recent_days].mean()
                        previous_avg = daily_counts[previous_days].mean()
                        
                        if previous_avg > 0:
                            change_pct = (recent_avg - previous_avg) / previous_avg * 100
                            metrics["recent_trend"] = {
                                "direction": "up" if change_pct > 5 else ("down" if change_pct < -5 else "stable"),
                                "percentage_change": round(change_pct, 2),
                                "recent_daily_avg": round(recent_avg, 2),
                                "previous_daily_avg": round(previous_avg, 2)
                            }
            except Exception as e:
                logger.warning(f"Error calculating trend metrics: {str(e)}")
        
        # Top categories
        for cat_col in ['category', 'subcategory']:
            if cat_col in df.columns:
                try:
                    cat_counts = df[cat_col].value_counts().head(5)
                    metrics[f"top_{cat_col}s"] = {
                        str(cat): {
                            "count": int(count),
                            "percentage": round(count / len(df) * 100, 2)
                        } for cat, count in cat_counts.items()
                    }
                except Exception as e:
                    logger.warning(f"Error calculating {cat_col} metrics: {str(e)}")
        
        # Top systems
        for sys_col in ['affected_system', 'system', 'application']:
            if sys_col in df.columns:
                try:
                    sys_counts = df[sys_col].value_counts().head(5)
                    metrics["top_systems"] = {
                        str(sys): {
                            "count": int(count),
                            "percentage": round(count / len(df) * 100, 2)
                        } for sys, count in sys_counts.items()
                    }
                    break  # Only use the first available system column
                except Exception as e:
                    logger.warning(f"Error calculating system metrics: {str(e)}")
        
        # Data quality metrics
        metrics["data_quality"] = {
            "missing_values_percentage": round(df.isnull().mean().mean() * 100, 2),
            "column_count": len(df.columns),
            "date_range_days": (df['created_date'].max() - df['created_date'].min()).days if 'created_date' in df.columns else None
        }
        
        return metrics
    
    def get_automation_suggestions(self, df: pd.DataFrame, max_suggestions: int = 5) -> Dict[str, Any]:
        """
        Generate automation suggestions from incident data.
        
        Args:
            df: DataFrame with incident data
            max_suggestions: Maximum number of suggestions to generate
            
        Returns:
            Dictionary with automation suggestions
        """
        # Check if data is sufficient for automation analysis
        sufficiency_check = check_data_sufficiency(df, "automation_opportunity")
        if not sufficiency_check["is_sufficient"]:
            logger.warning(f"Insufficient data for automation analysis: {sufficiency_check['reason']}")
            return {
                "success": False,
                "error": sufficiency_check["reason"],
                "recommendations": sufficiency_check["recommendations"]
            }
        
        # Prepare data for automation analysis
        try:
            processed_df, metadata = self.data_processor.prepare_data_for_analysis(df, "automation_opportunity")
            
            if processed_df is None:
                logger.warning(f"Data processing failed for automation analysis: {metadata.get('error', 'Unknown error')}")
                return metadata
            
            # Extract automation patterns from metadata
            patterns = metadata.get("identified_patterns", [])
            
            # Limit to max_suggestions
            if patterns and len(patterns) > max_suggestions:
                patterns = patterns[:max_suggestions]
            
            # Format the suggestions
            suggestions = []
            for pattern in patterns:
                suggestion = {
                    "name": pattern.get("category", "") + " - " + pattern.get("subcategory", "") if "category" in pattern else pattern.get("key_phrase", ""),
                    "frequency": pattern.get("frequency", 0),
                    "percentage": round(pattern.get("percentage", 0), 2),
                    "potential": pattern.get("automation_potential", "medium"),
                    "description": self._generate_automation_description(pattern)
                }
                suggestions.append(suggestion)
            
            result = {
                "success": True,
                "suggestions": suggestions,
                "insufficient_data": len(suggestions) == 0,
                "message": "No clear automation patterns detected" if len(suggestions) == 0 else None
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Error generating automation suggestions: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": f"Error generating automation suggestions: {str(e)}"
            }
    
    def _generate_automation_description(self, pattern: Dict[str, Any]) -> str:
        """
        Generate a description for an automation opportunity.
        
        Args:
            pattern: Dictionary with pattern information
            
        Returns:
            Description string
        """
        if "category" in pattern and "subcategory" in pattern:
            return f"Automate handling of {pattern['category']} - {pattern['subcategory']} incidents " + \
                   f"which account for {pattern['percentage']:.1f}% of all incidents. " + \
                   ("These incidents show consistent resolution patterns." if pattern.get("consistent_resolution") else "")
        
        elif "key_phrase" in pattern:
            return f"Automate incidents containing '{pattern['key_phrase']}' " + \
                   f"which appear in {pattern['percentage']:.1f}% of cases. " + \
                   ("These incidents show consistent resolution patterns." if pattern.get("consistent_resolution") else "")
        
        elif "resolution_phrase" in pattern:
            return f"Create automation based on resolution pattern: '{pattern['resolution_phrase']}' " + \
                   f"which is used in {pattern['percentage']:.1f}% of incidents."
        
        else:
            return f"Potential automation opportunity detected in {pattern.get('frequency', 0)} incidents."
    
    def get_resource_optimization_insights(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Generate resource optimization insights from incident data.
        
        Args:
            df: DataFrame with incident data
            
        Returns:
            Dictionary with resource optimization insights
        """
        # Check if data is sufficient for resource analysis
        sufficiency_check = check_data_sufficiency(df, "resource_analysis")
        if not sufficiency_check["is_sufficient"]:
            logger.warning(f"Insufficient data for resource analysis: {sufficiency_check['reason']}")
            return {
                "success": False,
                "error": sufficiency_check["reason"],
                "recommendations": sufficiency_check["recommendations"]
            }
        
        # Prepare data for resource analysis
        try:
            processed_df, metadata = self.data_processor.prepare_data_for_analysis(df, "resource_analysis")
            
            if processed_df is None:
                logger.warning(f"Data processing failed for resource analysis: {metadata.get('error', 'Unknown error')}")
                return metadata
            
            # Extract resource metrics from metadata
            resource_metrics = metadata.get("resource_metrics", {})
            workload_distribution = metadata.get("workload_distribution", {})
            resource_trends = metadata.get("resource_trends", {})
            
            # Analyze workload balance
            workload_analysis = self._analyze_workload_balance(workload_distribution)
            
            # Identify resource efficiency
            efficiency_analysis = self._analyze_resource_efficiency(resource_metrics)
            
            # Identify growth areas
            growth_analysis = self._analyze_resource_trends(resource_trends)
            
            result = {
                "success": True,
                "workload_analysis": workload_analysis,
                "efficiency_analysis": efficiency_analysis,
                "growth_analysis": growth_analysis,
                "resource_column": metadata.get("resource_column"),
                "total_resources": metadata.get("total_resources"),
                "top_resources": metadata.get("top_resources")
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Error generating resource optimization insights: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": f"Error generating resource optimization insights: {str(e)}"
            }
    
    def _analyze_workload_balance(self, workload_distribution: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze workload balance across resources.
        
        Args:
            workload_distribution: Dictionary with workload distribution metrics
            
        Returns:
            Dictionary with workload balance analysis
        """
        workload_analysis = {
            "balance_score": 0,
            "balance_level": "unknown",
            "findings": []
        }
        
        if not workload_distribution:
            return workload_analysis
        
        # Calculate balance score based on coefficient of variation
        # Lower CV means more balanced workload
        cv = workload_distribution.get("coefficient_of_variation", 1)
        
        if cv < 0.3:
            balance_level = "well_balanced"
            score = 80 + (0.3 - cv) * 66.7  # 80-100
        elif cv < 0.5:
            balance_level = "moderately_balanced"
            score = 60 + (0.5 - cv) * 100  # 60-80
        elif cv < 0.8:
            balance_level = "somewhat_imbalanced"
            score = 40 + (0.8 - cv) * 66.7  # 40-60
        elif cv < 1.2:
            balance_level = "imbalanced"
            score = 20 + (1.2 - cv) * 50  # 20-40
        else:
            balance_level = "highly_imbalanced"
            score = max(0, 20 - (cv - 1.2) * 10)  # 0-20
        
        workload_analysis["balance_score"] = min(100, max(0, round(score)))
        workload_analysis["balance_level"] = balance_level
        
        # Add findings based on metrics
        if cv > 0.5:
            workload_analysis["findings"].append(
                f"Workload is unevenly distributed (variation coefficient: {cv:.2f})"
            )
            workload_analysis["findings"].append(
                f"Some resources handle up to {workload_distribution.get('max', 0)} incidents, " +
                f"while others handle as few as {workload_distribution.get('min', 0)}"
            )
        else:
            workload_analysis["findings"].append(
                f"Workload is relatively well distributed (variation coefficient: {cv:.2f})"
            )
        
        return workload_analysis
    
    def _analyze_resource_efficiency(self, resource_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze resource efficiency.
        
        Args:
            resource_metrics: Dictionary with resource metrics
            
        Returns:
            Dictionary with resource efficiency analysis
        """
        efficiency_analysis = {
            "most_efficient_resources": [],
            "least_efficient_resources": [],
            "findings": []
        }
        
        if not resource_metrics:
            return efficiency_analysis
        
        # Extract resources with efficiency metrics
        resources_with_efficiency = {}
        for resource, metrics in resource_metrics.items():
            if "mean_resolution_hours" in metrics and "incident_count" in metrics and resource != "Others":
                resolution_hours = metrics["mean_resolution_hours"]
                incident_count = metrics["incident_count"]
                
                # Simple efficiency score: incident count / resolution time
                # Higher score means more incidents resolved in less time
                if resolution_hours > 0:
                    efficiency_score = incident_count / resolution_hours
                    resources_with_efficiency[resource] = {
                        "efficiency_score": efficiency_score,
                        "incident_count": incident_count,
                        "mean_resolution_hours": resolution_hours
                    }
        
        # Sort resources by efficiency score
        sorted_resources = sorted(
            resources_with_efficiency.items(),
            key=lambda x: x[1]["efficiency_score"],
            reverse=True
        )
        
        # Get top and bottom resources
        top_n = min(3, len(sorted_resources))
        if top_n > 0:
            efficiency_analysis["most_efficient_resources"] = [
                {
                    "resource": resource,
                    "efficiency_score": round(metrics["efficiency_score"], 2),
                    "incident_count": metrics["incident_count"],
                    "mean_resolution_hours": round(metrics["mean_resolution_hours"], 2)
                }
                for resource, metrics in sorted_resources[:top_n]
            ]
            
            efficiency_analysis["least_efficient_resources"] = [
                {
                    "resource": resource,
                    "efficiency_score": round(metrics["efficiency_score"], 2),
                    "incident_count": metrics["incident_count"],
                    "mean_resolution_hours": round(metrics["mean_resolution_hours"], 2)
                }
                for resource, metrics in sorted_resources[-top_n:]
            ]
            
            # Add findings
            if len(sorted_resources) >= 2:
                top_score = sorted_resources[0][1]["efficiency_score"]
                bottom_score = sorted_resources[-1][1]["efficiency_score"]
                
                if top_score > 0 and bottom_score > 0:
                    ratio = top_score / bottom_score
                    
                    if ratio > 3:
                        efficiency_analysis["findings"].append(
                            f"Significant efficiency gap: top resources are {ratio:.1f}x more efficient than bottom resources"
                        )
                    
                    # Specific findings about top performers
                    top_resource, top_metrics = sorted_resources[0]
                    efficiency_analysis["findings"].append(
                        f"{top_resource} shows highest efficiency: {top_metrics['incident_count']} incidents " +
                        f"with {top_metrics['mean_resolution_hours']:.1f} hours average resolution time"
                    )
        
        return efficiency_analysis
    
    def _analyze_resource_trends(self, resource_trends: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze resource workload trends.
        
        Args:
            resource_trends: Dictionary with resource trend information
            
        Returns:
            Dictionary with trend analysis
        """
        trend_analysis = {
            "growing_workloads": [],
            "declining_workloads": [],
            "findings": []
        }
        
        if not resource_trends or "trends" not in resource_trends:
            return trend_analysis
        
        # Analyze trends for each resource
        for resource, trend in resource_trends.get("trends", {}).items():
            direction = trend.get("direction")
            change_pct = trend.get("change_percentage", 0)
            
            if direction == "increasing" and change_pct > 20:
                trend_analysis["growing_workloads"].append({
                    "resource": resource,
                    "change_percentage": round(change_pct, 2),
                    "monthly_data": trend.get("monthly_data", [])
                })
            elif direction == "decreasing" and change_pct < -20:
                trend_analysis["declining_workloads"].append({
                    "resource": resource,
                    "change_percentage": round(change_pct, 2),
                    "monthly_data": trend.get("monthly_data", [])
                })
        
        # Add summary findings
        if trend_analysis["growing_workloads"]:
            resources = ", ".join([item["resource"] for item in trend_analysis["growing_workloads"][:3]])
            trend_analysis["findings"].append(
                f"Resources with significantly increasing workload: {resources}"
            )
        
        if trend_analysis["declining_workloads"]:
            resources = ", ".join([item["resource"] for item in trend_analysis["declining_workloads"][:3]])
            trend_analysis["findings"].append(
                f"Resources with significantly decreasing workload: {resources}"
            )
        
        # Add time period context
        if "first_month" in resource_trends and "last_month" in resource_trends:
            trend_analysis["period"] = {
                "first_month": resource_trends["first_month"],
                "last_month": resource_trends["last_month"]
            }
        
        return trend_analysis
    


def generate_insights(df, key_columns):
    """
    Generate insights from incident data.
    
    Args:
        df: DataFrame with incident data
        key_columns: Dictionary mapping standard column names to actual column names
    
    Returns:
        List of insights
    """
    try:
        # Create a basic set of insights based on the data
        insights = []
        
        # Only proceed if we have enough data
        if df is None or df.empty or len(df) < 10:
            return insights
        
        # 1. Volume insight
        total_incidents = len(df)
        insights.append({
            'title': 'Incident Volume',
            'content': f"Analysis based on {total_incidents} incidents."
        })
        
        # 2. Time-based insights
        date_col = key_columns.get('timestamp')
        if date_col and date_col in df.columns:
            try:
                # Ensure date column is datetime
                if df[date_col].dtype != 'datetime64[ns]':
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                
                # Get date range
                min_date = df[date_col].min()
                max_date = df[date_col].max()
                date_range = (max_date - min_date).days
                
                if date_range > 0:
                    avg_daily = total_incidents / date_range
                    insights.append({
                        'title': 'Time Analysis',
                        'content': f"Data spans {date_range} days from {min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')} with an average of {avg_daily:.1f} incidents per day."
                    })
                    
                    # Check for day of week pattern
                    try:
                        day_counts = df[date_col].dt.dayofweek.value_counts().sort_index()
                        weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                        max_day = day_counts.idxmax()
                        max_day_pct = day_counts[max_day] / day_counts.sum() * 100
                        
                        if max_day_pct > 25:  # Significant peak on one day
                            insights.append({
                                'title': 'Day of Week Pattern',
                                'content': f"{weekdays[max_day]}s account for {max_day_pct:.1f}% of all incidents, suggesting higher activity on this day."
                            })
                    except Exception:
                        pass
            except Exception:
                pass
        
        # 3. Priority insights
        priority_col = key_columns.get('priority')
        if priority_col and priority_col in df.columns:
            try:
                priority_counts = df[priority_col].value_counts()
                top_priority = priority_counts.index[0]
                top_priority_pct = priority_counts[top_priority] / priority_counts.sum() * 100
                
                insights.append({
                    'title': 'Priority Distribution',
                    'content': f"Most common priority is '{top_priority}' ({top_priority_pct:.1f}% of incidents)."
                })
                
                # Identify critical/high priority incidents
                high_priorities = [p for p in priority_counts.index if str(p).lower() in ['critical', 'high', 'p1', 'p2', '1', '2']]
                if high_priorities:
                    high_count = sum(priority_counts[p] for p in high_priorities)
                    high_pct = high_count / priority_counts.sum() * 100
                    
                    insights.append({
                        'title': 'High Priority Incidents',
                        'content': f"High priority incidents account for {high_pct:.1f}% of total volume."
                    })
            except Exception:
                pass


        # 4. Category insights
        category_col = key_columns.get('category')
        if category_col and category_col in df.columns:
            try:
                category_counts = df[category_col].value_counts()
                if len(category_counts) > 0:
                    top_category = category_counts.index[0]
                    top_category_pct = category_counts[top_category] / category_counts.sum() * 100
                    
                    insights.append({
                        'title': 'Top Incident Category',
                        'content': f"Most common category is '{top_category}' ({top_category_pct:.1f}% of incidents)."
                    })
                    
                    # Check if there's a dominant category
                    if top_category_pct > 50:
                        insights.append({
                            'title': 'Category Dominance',
                            'content': f"'{top_category}' is the dominant category, representing over half of all incidents."
                        })
            except Exception:
                pass
                
        # 5. Resolution time insights
        resolution_col = key_columns.get('resolution_time')
        if resolution_col and resolution_col in df.columns:
            try:
                # Filter out invalid values
                valid_resolution = df[df[resolution_col] > 0][resolution_col]
                if len(valid_resolution) > 0:
                    avg_resolution = valid_resolution.mean()
                    median_resolution = valid_resolution.median()
                    
                    if avg_resolution > median_resolution * 2:
                        insights.append({
                            'title': 'Resolution Time Distribution',
                            'content': f"Resolution time is skewed with average ({avg_resolution:.1f}) much higher than median ({median_resolution:.1f}), indicating some very long-running incidents."
                        })
                    else:
                        insights.append({
                            'title': 'Resolution Time',
                            'content': f"Average resolution time is {avg_resolution:.1f} hours."
                        })
            except Exception:
                pass
        
        return insights
    
    except Exception as e:
        import logging
        logging.error(f"Error generating insights: {str(e)}")
        return []
                

# Add this at the module level in analysis/insights_generator.py

generate_overview_insights = generate_insights